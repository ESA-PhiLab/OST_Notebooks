{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open SAR Toolkit (OST) - Jupyter Notebook\n",
    "## Process latest Sentinel-1 GRD product for a given point\n",
    "\n",
    "This notebook introduces you to a very basic example of how to use OST for the processing of a single scene. In particluar, you will go through the whole workflow that creates a Sentinel-1 Analysis-Ready-Data product for the latest scene for a given Point of Interest. You will:\n",
    "\n",
    "- **Step 1:** Set the processing parameters\n",
    "- **Step 2:** Execute a Data Inventory on scihub \n",
    "- **Step 3:** Select the latest scene (a bit of pre-cooked python-pandas here)\n",
    "- **Step 4:** Download the latest scene\n",
    "- **Step 5:** Process the latest scene to an Analysis-Ready-Data product\n",
    "- **Step 6:** Visualize the scene as an RGB image inside the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (just execute) import python libs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python standard libs\n",
    "import os, glob\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# OST libs\n",
    "from ost.helpers import scihub, vector as vec\n",
    "from ost.s1.metadata import s1Metadata\n",
    "from ost.s1 import search, refine, download, grd2Ard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Provide the latitude and longitude of your point of interest as well as your project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide a latitude and longitude\n",
    "# this example points to Rome, Italy\n",
    "lon = 12.5113\n",
    "lat = 41.8919\n",
    "\n",
    "# output Directory\n",
    "prjDir = '/path/to/project'\n",
    "\n",
    "# processing parameters\n",
    "outResolution = 50                          # resolution of the output product in meters\n",
    "lsMap = False                               # layover/shadow mask generation (Boolean)\n",
    "spkFlt = False                              # speckle filtering (Boolean)\n",
    "\n",
    "# 3 different output product type are available \n",
    "#  - RTC: radiometrically corrected for slope\n",
    "#  - GTCgamma: geometrically terrain corrected and compensated for ellipsoid curvature\n",
    "#  - GTCsigma: geometrically terrain corrected\n",
    "outPrdType = 'GTCgamma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (just execute) create the directory structure for the project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create project dir if not existent\n",
    "os.makedirs(prjDir, exist_ok=True)\n",
    "\n",
    "# this is where we download the original scenes\n",
    "dwnDir = '{}/download'.format(prjDir)\n",
    "os.makedirs(dwnDir, exist_ok=True)\n",
    "\n",
    "# this folder will be used for the inventory shape files\n",
    "invDir = '{}/inventory'.format(prjDir)\n",
    "os.makedirs(invDir, exist_ok=True)\n",
    "\n",
    "# set output filepath and delete any existing files\n",
    "outputInv = '{}/fullInventory.shp'.format(invDir)\n",
    "\n",
    "# this folder will be used for the processed data\n",
    "prcDir = '{}/processed'.format(prjDir)\n",
    "os.makedirs(prcDir, exist_ok=True)\n",
    "\n",
    "# this folder will be used for temporary data\n",
    "tmpDir = '{}/tmp'.format(prjDir)\n",
    "os.makedirs(tmpDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (just execute) run search query on ESA's scihub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create AOI string for the scihub query from scratch (OST only supports polygons)\n",
    "aoiStr = \"( footprint:\\\"Intersects({}, {})\\\")\".format(lat, lon)\n",
    "\n",
    "# create startDate (30 days before today)\n",
    "startDate = (datetime.today() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "# create query string for TOI (endDate is automatically set to \"now\")\n",
    "toiStr = scihub.createToiStr(startDate)\n",
    "\n",
    "# we specify the product type and beam mode\n",
    "prdType = 'GRD' # GRD = Ground Range Detected\n",
    "beamMode = 'IW' # IW = Interferometric Wideswath Beam\n",
    "prodSpecsStr = scihub.createS1ProdSpecs(prdType, '*', beamMode)\n",
    "\n",
    "# create complete query (merge parts together)\n",
    "query = scihub.createQuery('Sentinel-1', aoiStr, toiStr, prodSpecsStr)\n",
    "uname, pword = scihub.askScihubCreds()\n",
    "\n",
    "if os.path.isfile(output):\n",
    "    for file in glob.glob(outputInv):\n",
    "        os.remove(file)\n",
    "\n",
    "# execute search with OST s1Scihub function   \n",
    "search.s1Scihub(query, output, uname, pword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. (just execute) Select latest scene and plot on a world map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (13, 13)\n",
    "\n",
    "# we need to convert our point to a shapefile\n",
    "vec.llPoint2shp(lat, lon, '{}/.aoiPoint.shp'.format(prjDir))\n",
    "aoi = '{}/.aoiPoint.shp'.format(prjDir)\n",
    "\n",
    "# re-read output file into a GeoDataFrame for further steps\n",
    "footprintGdf = refine.readS1Inventory(outputInv)\n",
    "# get the latest scene\n",
    "footprintGdf = footprintGdf[footprintGdf.endposition == footprintGdf.endposition.max()]\n",
    "\n",
    "print(' INFO: Latest Sentinel product'\n",
    "      ' for Lat: {} and Lon: {}'\n",
    "      ' found from {}'.format(lat, lon, footprintGdf.endposition.max()))\n",
    "\n",
    "# plot latest scene\n",
    "vec.plotInv(aoi, footprintGdf, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (just execute) derive some basic metadata of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the scene id from the dataframe\n",
    "scene = s1Metadata(footprintGdf.identifier.values[0])\n",
    "\n",
    "print(' Some metadata for the scene to process')\n",
    "scene.s1Info()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. (just execute) download the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download.downloadS1(footprintGdf, dwnDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. (just execute) process scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to the raw scene that had been downloaded before\n",
    "# NOTE, we need a class object that we created under 5.\n",
    "scenePath = [scene.s1DwnPath(dwnDir)]\n",
    "\n",
    "# for the filename we extract the acquistion date of the scene\n",
    "acqDate = scene.start_date\n",
    "\n",
    "# we define a tmpDir\n",
    "#tmpDir = '/ram' # we could use a ramdisk (tmpfs) in order to speed up processing\n",
    "tmpDir = '/tmp'\n",
    "\n",
    "# run the main routine (note that the path to the scene needs to be given as a list)\n",
    "grd2Ard.grd2Ard(scenePath, prcDir, acqDate, tmpDir, outResolution, outPrdType, lsMap, spkFlt)\n",
    "\n",
    "# let's create standard rgb composite, i.e. create a ratio and group the data in a vrt file\n",
    "fileName = '{}.{}'.format(acqDate, outPrdType)\n",
    "grd2Ard.grd2RGB(prcDir, fileName, prcDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. (just execute) visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np \n",
    "from ost.helpers import raster as ras  \n",
    "pylab.rcParams['figure.figsize'] = (17, 17)\n",
    "\n",
    "def norm(band):\n",
    "    band_min, band_max = np.percentile(band, 2), np.percentile(band, 98)\n",
    "    return ((band - band_min)/(band_max - band_min))\n",
    "\n",
    "filepath = '{}/{}.{}.vrt'.format(prcDir, acqDate, outPrdType)\n",
    "with rasterio.open(filepath) as src:\n",
    "    array = src.read()\n",
    "\n",
    "r = norm(ras.scale2Int(array[0], -18, 0, 'uint8'))\n",
    "g = norm(ras.scale2Int(array[1], -25, -5, 'uint8'))\n",
    "b = norm(ras.scale2Int(array[2], 1, 15, 'uint8'))\n",
    "img = np.dstack((r,g,b))\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
